{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Phi-3-vision-128k-instruct Huggingface](https://huggingface.co/microsoft/Phi-3-vision-128k-instruct)"
      ],
      "metadata": {
        "id": "7vuXmbxO7Tv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install and Auto restart\n",
        "import os\n",
        "root_path=os.getcwd()\n",
        "# root_path=\"/content\"\n",
        "base_path=f\"{root_path}\"\n",
        "\n",
        "requirements_content = \"\"\"accelerate==0.30.1\n",
        "flash_attn==2.5.8\n",
        "numpy==1.24.4\n",
        "Pillow==10.1.0\n",
        "Requests==2.31.0\n",
        "transformers==4.40.2\n",
        "gradio==4.29.0\n",
        "pydub==0.25.1\n",
        "edge-tts\n",
        "# gradio==4.15.0\n",
        "# Pillow==10.3.0\n",
        "# torch==2.3.0\n",
        "# torchvision==0.18.0\n",
        "\"\"\"\n",
        "with open(f\"{base_path}/requirements.txt\", \"w\") as file:\n",
        "    file.write(requirements_content)\n",
        "\n",
        "print(f\"File '{base_path}/requirements.txt' has been successfully created with the specified contents.\")\n",
        "\n",
        "from google.colab import output\n",
        "# output.eval_js('new Audio(\"https://github.com/neuralfalcon/Roop-Image-FaceSwap/raw/main/start.mp3\").play()')\n",
        "!pip install -r $base_path/requirements.txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "# output.eval_js('new Audio(\"https://github.com/neuralfalcon/Roop-Image-FaceSwap/raw/main/install_voice.mp3\").play()')\n",
        "import time\n",
        "time.sleep(6)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "4Da9fw0Jf6jQ",
        "outputId": "247f8b9c-c201-4b75-e3be-985bfb6e8353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9f201ee25ed6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# output.eval_js('new Audio(\"https://github.com/neuralfalcon/Roop-Image-FaceSwap/raw/main/install_voice.mp3\").play()')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate==0.30.1\n",
        "!pip install flash_attn==2.5.8\n",
        "!pip install numpy==1.24.4\n",
        "!pip install Pillow==10.1.0\n",
        "!pip install Requests==2.31.0\n",
        "!pip install transformers==4.40.2\n",
        "!pip install gradio==4.29.0\n",
        "!pip install pydub==0.25.1\n",
        "!pip install edge-tts\n",
        "# gradio==4.15.0\n",
        "# Pillow==10.3.0\n",
        "# torch==2.3.0\n",
        "# torchvision==0.18.0"
      ],
      "metadata": {
        "id": "FDTyKjVRBcci",
        "outputId": "9e181377-610f-4bbb-a23b-0ce8a71c1526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.30.1\n",
            "  Using cached accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.30.1) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.1) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.30.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1) (2025.4.26)\n",
            "Using cached accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.6.0\n",
            "    Uninstalling accelerate-1.6.0:\n",
            "      Successfully uninstalled accelerate-1.6.0\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate",
                  "nvidia"
                ]
              },
              "id": "278b3dbe26654e1089f7409409d0b71c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash_attn==2.5.8\n",
            "  Using cached flash_attn-2.5.8.tar.gz (2.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash_attn==2.5.8) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn==2.5.8) (0.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from flash_attn==2.5.8) (24.2)\n",
            "Collecting ninja (from flash_attn==2.5.8)\n",
            "  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==2.5.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash_attn==2.5.8) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash_attn==2.5.8) (3.0.2)\n",
            "Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Building wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25lcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25hCollecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c8afd151709249f9bf1fbae1954a7094"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==10.1.0\n",
            "  Using cached Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Using cached Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "Successfully installed Pillow-10.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "60abe6638d524b61a4689b972136b185"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Requests==2.31.0\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0) (2025.4.26)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Installing collected packages: Requests\n",
            "  Attempting uninstall: Requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Requests-2.31.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "4e701c82cc3344fb9b2ca90a119d7400"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.40.2\n",
            "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (2.31.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.2)\n",
            "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.2) (2025.4.26)\n",
            "Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
            "Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.40.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "f24a54d324f64fbeb8b63c7f701e295f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==4.29.0\n",
            "  Using cached gradio-4.29.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.29.0)\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (5.5.0)\n",
            "Collecting fastapi (from gradio==4.29.0)\n",
            "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==4.29.0)\n",
            "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.16.1 (from gradio==4.29.0)\n",
            "  Using cached gradio_client-0.16.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (0.30.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==4.29.0)\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (3.10.0)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (1.24.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (10.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (2.11.4)\n",
            "Collecting pydub (from gradio==4.29.0)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio==4.29.0)\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio==4.29.0)\n",
            "  Using cached ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==4.29.0)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.29.0)\n",
            "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (4.13.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0) (2.4.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.29.0)\n",
            "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.16.1->gradio==4.29.0) (2025.3.2)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.1->gradio==4.29.0)\n",
            "  Using cached websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0) (1.37.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.29.0) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio==4.29.0) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio==4.29.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio==4.29.0) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0) (13.9.4)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->gradio==4.29.0)\n",
            "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.29.0) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0) (2.19.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio==4.29.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.29.0) (3.4.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0) (0.1.2)\n",
            "Using cached gradio-4.29.0-py3-none-any.whl (12.3 MB)\n",
            "Using cached gradio_client-0.16.1-py3-none-any.whl (314 kB)\n",
            "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Using cached ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "Using cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "Using cached websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "Installing collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.13.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "dataproc-spark-connect 0.7.2 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-4.29.0 gradio-client-0.16.1 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.12.0 uvicorn-0.34.2 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "markupsafe"
                ]
              },
              "id": "9b12e482f21f4100bbb46ec6bc601209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub==0.25.1 in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Collecting edge-tts\n",
            "  Using cached edge_tts-7.0.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.15)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.4.26)\n",
            "Collecting srt<4.0.0,>=3.4.1 (from edge-tts)\n",
            "  Using cached srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->edge-tts) (3.10)\n",
            "Using cached edge_tts-7.0.2-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=5d8c46ef39cd182ffd8b8683d864673d65ab4b88d69da73c0110b8afa64de88d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, edge-tts\n",
            "Successfully installed edge-tts-7.0.2 srt-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r $base_path/requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vKIRJEe8_lxC",
        "outputId": "e9447230-ad82-4e9c-e0de-9cad3145398f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.30.1 (from -r /content/requirements.txt (line 1))\n",
            "  Using cached accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting flash_attn==2.5.8 (from -r /content/requirements.txt (line 2))\n",
            "  Using cached flash_attn-2.5.8.tar.gz (2.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.24.4 (from -r /content/requirements.txt (line 3))\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting Pillow==10.1.0 (from -r /content/requirements.txt (line 4))\n",
            "  Using cached Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting Requests==2.31.0 (from -r /content/requirements.txt (line 5))\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting transformers==4.40.2 (from -r /content/requirements.txt (line 6))\n",
            "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
            "Collecting gradio==4.29.0 (from -r /content/requirements.txt (line 7))\n",
            "  Using cached gradio-4.29.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydub==0.25.1 (from -r /content/requirements.txt (line 8))\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting edge-tts (from -r /content/requirements.txt (line 9))\n",
            "  Using cached edge_tts-7.0.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r /content/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r /content/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r /content/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r /content/requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r /content/requirements.txt (line 1)) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r /content/requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn==2.5.8->-r /content/requirements.txt (line 2)) (0.8.1)\n",
            "Collecting ninja (from flash_attn==2.5.8->-r /content/requirements.txt (line 2))\n",
            "  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0->-r /content/requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0->-r /content/requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0->-r /content/requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from Requests==2.31.0->-r /content/requirements.txt (line 5)) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2->-r /content/requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2->-r /content/requirements.txt (line 6)) (2024.11.6)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.2->-r /content/requirements.txt (line 6))\n",
            "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.2->-r /content/requirements.txt (line 6)) (4.67.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (5.5.0)\n",
            "Collecting fastapi (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.16.1 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached gradio_client-0.16.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (2.11.4)\n",
            "Collecting python-multipart>=0.0.9 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r /content/requirements.txt (line 7)) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.16.1->gradio==4.29.0->-r /content/requirements.txt (line 7)) (2025.3.2)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.1->gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts->-r /content/requirements.txt (line 9)) (3.11.15)\n",
            "Collecting srt<4.0.0,>=3.4.1 (from edge-tts->-r /content/requirements.txt (line 9))\n",
            "  Using cached srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts->-r /content/requirements.txt (line 9)) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts->-r /content/requirements.txt (line 9)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts->-r /content/requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts->-r /content/requirements.txt (line 9)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts->-r /content/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts->-r /content/requirements.txt (line 9)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts->-r /content/requirements.txt (line 9)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts->-r /content/requirements.txt (line 9)) (1.20.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (1.37.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r /content/requirements.txt (line 7)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r /content/requirements.txt (line 7)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1)) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.30.1->-r /content/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r /content/requirements.txt (line 7)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r /content/requirements.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r /content/requirements.txt (line 7)) (13.9.4)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->gradio==4.29.0->-r /content/requirements.txt (line 7))\n",
            "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.29.0->-r /content/requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r /content/requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r /content/requirements.txt (line 7)) (2.19.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio==4.29.0->-r /content/requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r /content/requirements.txt (line 7)) (0.1.2)\n",
            "Using cached accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Using cached Pillow-10.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
            "Using cached gradio-4.29.0-py3-none-any.whl (12.3 MB)\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Using cached gradio_client-0.16.1-py3-none-any.whl (314 kB)\n",
            "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Using cached edge_tts-7.0.2-py3-none-any.whl (26 kB)\n",
            "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Using cached ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "Using cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "Using cached websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "Building wheels for collected packages: flash_attn, srt\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After runtime disconneted Run from here "
      ],
      "metadata": {
        "id": "6Zj1jLWpkfme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <-- Play the audio { display-mode: \"form\" }\n",
        "\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then run the cell below</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "1wAV2wi93c93",
        "outputId": "93bc77a2-d5d9-443b-e5c9-5734828ce7ff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<b>Press play on the music player to keep the tab alive, then run the cell below</b><br/>\n",
              "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download /microsoft/Phi-3-vision-128k-instruct\n",
        "from tqdm import tqdm\n",
        "import urllib\n",
        "import os\n",
        "import shutil\n",
        "def conditional_download(url, download_file_path):\n",
        "    print(f\"Downloading {os.path.basename(download_file_path)}\")\n",
        "    base_path = os.path.dirname(download_file_path)\n",
        "\n",
        "    if not os.path.exists(base_path):\n",
        "        os.makedirs(base_path)\n",
        "\n",
        "    if os.path.exists(download_file_path):\n",
        "        os.remove(download_file_path)\n",
        "\n",
        "    try:\n",
        "        request = urllib.request.urlopen(url)  # type: ignore[attr-defined]\n",
        "        total = int(request.headers.get('Content-Length', 0))\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"Error: Unable to open the URL - {url}\")\n",
        "        print(f\"Reason: {e.reason}\")\n",
        "        return\n",
        "\n",
        "    with tqdm(total=total, desc='Downloading', unit='B', unit_scale=True, unit_divisor=1024) as progress:\n",
        "        try:\n",
        "            urllib.request.urlretrieve(url, download_file_path, reporthook=lambda count, block_size, total_size: progress.update(block_size))  # type: ignore[attr-defined]\n",
        "        except urllib.error.URLError as e:\n",
        "            print(f\"Error: Failed to download the file from the URL - {url}\")\n",
        "            print(f\"Reason: {e.reason}\")\n",
        "            return\n",
        "\n",
        "    print(f\"Download successful!\")\n",
        "    print(f\"URL: {url}\")\n",
        "    print(f\"Save at: {download_file_path}\")\n",
        "\n",
        "\n",
        "#set up base_path\n",
        "import os\n",
        "root_path=os.getcwd()\n",
        "# root_path=\"/content\"\n",
        "base_path=f\"{root_path}\"\n",
        "\n",
        "\n",
        "\n",
        "download_dir=f\"{base_path}/microsoft/Phi-3-vision-128k-instruct\"\n",
        "if not os.path.exists(download_dir):\n",
        "    os.makedirs(download_dir)\n",
        "download_list = [\n",
        "    \"config.json\",\n",
        "    \"configuration_phi3_v.py\",\n",
        "    \"image_embedding_phi3_v.py\",\n",
        "    \"image_processing_phi3_v.py\",\n",
        "    \"model.safetensors.index.json\",\n",
        "    \"modeling_phi3_v.py\",\n",
        "    \"preprocessor_config.json\",\n",
        "    \"processing_phi3_v.py\",\n",
        "    \"sample_inference.py\",\n",
        "    \"special_tokens_map.json\",\n",
        "    \"tokenizer.json\",\n",
        "    \"tokenizer_config.json\",\n",
        "    \"model-00001-of-00002.safetensors\",\n",
        "    \"model-00002-of-00002.safetensors\"\n",
        "]\n",
        "base_url=\"https://huggingface.co/microsoft/Phi-3-vision-128k-instruct/resolve/main\"\n",
        "# fix_url=\"https://raw.githubusercontent.com/neuralfalcon/Phi-3-vision-128k-instruct-colab/main/\"\n",
        "for i in download_list:\n",
        "  # if i==\"config.json\" or i==\"modeling_phi3_v.py\":\n",
        "  #   file_url=f\"{fix_url}/{i}\"\n",
        "  # else:\n",
        "  #   file_url=f\"{base_url}/{i}\"\n",
        "  file_url=f\"{base_url}/{i}\"\n",
        "  download_file_path=f\"{download_dir}/{i}\"\n",
        "  conditional_download(file_url, download_file_path)\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "P12E4WjghVQO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title import /microsoft/Phi-3-vision-128k-instruct\n",
        "\n",
        "import os\n",
        "root_path=os.getcwd()\n",
        "# root_path=\"/content\"\n",
        "base_path=f\"{root_path}\"\n",
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import AutoProcessor\n",
        "import os\n",
        "model_id = f\"{base_path}/microsoft/Phi-3-vision-128k-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", trust_remote_code=True, torch_dtype=\"auto\", _attn_implementation=\"eager\")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "4ec57668444e4ddb9cffb9a09782528c",
            "87a698a12afd4ad8807e23fd01fde6d4",
            "433f5f31986740b08ea2441d343329e5",
            "3ee9a98ad3c447d5a5726a2142ac7e7f",
            "26147d1049b44c7d838254b7a7944a8a",
            "88eb60bdc17c429186808823398f7675",
            "a729d4d1bc504a5788636c30d163681c",
            "c69c9401a0344dddb9cac005807e3042",
            "f65900fe293b4ea3adf27097a943fdcb",
            "f4dfdbb13da74a2e93cdf676dccc6397",
            "534c8977fb9a46bfa2de1e3725f3d735"
          ]
        },
        "id": "75S2wrFliCEx",
        "outputId": "6891dfb9-0823-400f-e6f4-6ab66910e53e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ec57668444e4ddb9cffb9a09782528c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 46.12 MiB is free. Process 42410 has 14.69 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 28.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-435c792325c3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/microsoft/Phi-3-vision-128k-instruct\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attn_implementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             return model_class.from_pretrained(\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m             )\n\u001b[1;32m    566\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_tuple\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# fallback to the last dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlast_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;31m# fallback to buffer dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4399\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4400\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4831\u001b[0m         )\n\u001b[1;32m   4832\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_device_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4833\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4835\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_disk_only_shard_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharded_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# in int/uint/bool and not cast them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             if (\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0mkeep_in_fp32_modules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 and any(\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 46.12 MiB is free. Process 42410 has 14.69 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 28.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Main code\n",
        "temp_image=\"\"\n",
        "def ask_question(question=\"What is shown in this image?\",user_image=\"\"):\n",
        "  global temp_image\n",
        "  if os.path.exists(user_image):\n",
        "    image = Image.open(user_image)\n",
        "    temp_image=user_image\n",
        "  elif os.path.exists(temp_image):\n",
        "    image = Image.open(temp_image)\n",
        "  else:\n",
        "    return \"Please upload a image\"\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"user\", \"content\": f\"<|image_1|>\\n{question}\"},\n",
        "      # {\"role\": \"assistant\", \"content\": \"The chart displays the percentage of respondents who agree with various statements about their preparedness for meetings. It shows five categories: 'Having clear and pre-defined goals for meetings', 'Knowing where to find the information I need for a meeting', 'Understanding my exact role and responsibilities when I'm invited', 'Having tools to manage admin tasks like note-taking or summarization', and 'Having more focus time to sufficiently prepare for meetings'. Each category has an associated bar indicating the level of agreement, measured on a scale from 0% to 100%.\"},\n",
        "      # {\"role\": \"user\", \"content\": \"Provide insightful questions to spark discussion.\"}\n",
        "  ]\n",
        "\n",
        "  # url = \"https://assets-c4akfrf5b4d3f4b7.z01.azurefd.net/assets/2024/04/BMDataViz_661fb89f3845e.png\"\n",
        "  # image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "\n",
        "  prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "  inputs = processor(prompt, [image], return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "  generation_args = {\n",
        "      \"max_new_tokens\": 500,\n",
        "      \"temperature\": 0.0,\n",
        "      \"do_sample\": False,\n",
        "  }\n",
        "\n",
        "  generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
        "\n",
        "  # remove input tokens\n",
        "  generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
        "  response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "  # print(response)\n",
        "  return response.strip()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def display_resized_image(image_path, max_size=(800, 800)):\n",
        "    \"\"\"\n",
        "    Reads an image from the given path, resizes it to fit within the specified max size,\n",
        "    and displays it using Matplotlib.\n",
        "\n",
        "    Parameters:\n",
        "    - image_path: str, path to the image file.\n",
        "    - max_size: tuple, (width, height) maximum size for the resized image. Default is (800, 800).\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Resize the image to fit within the max_size, maintaining the aspect ratio\n",
        "    image.thumbnail(max_size, Image.LANCZOS)\n",
        "\n",
        "    # Display the image using Matplotlib\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Hide the axes\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "t9AM5Ki7lewv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_image = ''  # @param {type: \"string\"}\n",
        "question = ''  # @param {type: \"string\"}\n",
        "\n",
        "answer=ask_question(question,user_image)\n",
        "display_resized_image(user_image)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "cellView": "form",
        "id": "aUJ2KRW2muab",
        "outputId": "ceaf965f-9396-4c25-b1b9-66b603155864"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'read'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3510\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'seek'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f0746259ff6d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mask_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdisplay_resized_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-88c497079b20>\u001b[0m in \u001b[0;36mdisplay_resized_image\u001b[0;34m(image_path, max_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \"\"\"\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Resize the image to fit within the max_size, maintaining the aspect ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3511\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use as gradio chatbot\n",
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def add_message(history, message):\n",
        "    if \"files\" in message and message[\"files\"]:\n",
        "        for file in message[\"files\"]:\n",
        "            history.append(((file,), None))\n",
        "    if \"text\" in message and message[\"text\"] is not None:\n",
        "        history.append((message[\"text\"], None))\n",
        "    return history, gr.update(value=None, interactive=True)\n",
        "\n",
        "def bot(history):\n",
        "    # response = \"**That's cool!**\"\n",
        "\n",
        "    # Extract the last file path and last message\n",
        "    last_file_path = None\n",
        "    last_message = None\n",
        "    for entry in reversed(history):\n",
        "        if last_file_path is None and isinstance(entry[0], tuple):\n",
        "            last_file_path = entry[0][0]\n",
        "        if last_message is None and isinstance(entry[0], str):\n",
        "            last_message = entry[0]\n",
        "        if last_file_path and last_message:\n",
        "            break\n",
        "\n",
        "    if last_file_path:\n",
        "        print(\"Last file path:\", last_file_path)\n",
        "        user_image=last_file_path\n",
        "    else:\n",
        "        user_image=\"\"\n",
        "    if last_message:\n",
        "        print(\"Last message:\", last_message)\n",
        "        question=last_message\n",
        "    else:\n",
        "        question=\"What is shown in this image?\"\n",
        "\n",
        "    response=ask_question(question,user_image)\n",
        "    history.append((\"\", \"\"))\n",
        "    for character in response:\n",
        "        history[-1] = (history[-1][0], history[-1][1] + character)\n",
        "        time.sleep(0.05)\n",
        "        yield history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(\n",
        "        [],\n",
        "        elem_id=\"chatbot\",\n",
        "        bubble_full_width=False\n",
        "    )\n",
        "\n",
        "    chat_input = gr.MultimodalTextbox(\n",
        "        interactive=True, file_types=[\"image\"], placeholder=\"Enter message or upload file...\", show_label=False\n",
        "    )\n",
        "\n",
        "    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n",
        "    bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n",
        "    bot_msg.then(lambda: gr.update(interactive=True), None, [chat_input])\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wiyFC2zY3TQ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "646a4a95-7d81-4b03-e7ba-9ef8bc428d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://dc0f685bab95b6785a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dc0f685bab95b6785a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This part for realtime talking with the model"
      ],
      "metadata": {
        "id": "AgJJZZqj3fz3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "nQutAlv3HHSm",
        "outputId": "db219cc0-8d18-4959-c8fb-b7ea8e12829b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is Phi-3-vision-128k-instruct Demo']\n",
            "edge-tts  --rate=+0% --voice en-US-AriaNeural --text \"This is Phi-3-vision-128k-instruct Demo\" --write-media /content/audio/233e7f46.mp3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#@title <-- Just run the cell (config edge TTS)\n",
        "def calculate_rate_string(input_value):\n",
        "    rate = (input_value - 1) * 100\n",
        "    sign = '+' if input_value >= 1 else '-'\n",
        "    return f\"{sign}{abs(int(rate))}\"\n",
        "\n",
        "\n",
        "def make_chunks(input_text, language):\n",
        "    language=\"English\"\n",
        "    if language == \"English\":\n",
        "      temp_list = input_text.strip().split(\".\")\n",
        "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
        "      if temp_list[-1].strip():\n",
        "          filtered_list.append(temp_list[-1].strip())\n",
        "      return filtered_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import uuid\n",
        "def tts_file_name(text):\n",
        "    if text.endswith(\".\"):\n",
        "        text = text[:-1]\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = text.replace(\" \",\"_\")\n",
        "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
        "    random_string = uuid.uuid4().hex[:8].upper()\n",
        "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
        "    return file_name\n",
        "\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "import os\n",
        "def merge_audio_files(audio_paths, output_path):\n",
        "    # Initialize an empty AudioSegment\n",
        "    merged_audio = AudioSegment.silent(duration=0)\n",
        "\n",
        "    # Iterate through each audio file path\n",
        "    for audio_path in audio_paths:\n",
        "        # Load the audio file using Pydub\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "        # Append the current audio file to the merged_audio\n",
        "        merged_audio += audio\n",
        "\n",
        "    # Export the merged audio to the specified output path\n",
        "    merged_audio.export(output_path, format=\"mp3\")\n",
        "\n",
        "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
        "  print(chunks_list)\n",
        "  if len(chunks_list)>1:\n",
        "    chunk_audio_list=[]\n",
        "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
        "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
        "    os.mkdir(\"/content/edge_tts_voice\")\n",
        "    k=1\n",
        "    for i in chunks_list:\n",
        "      print(i)\n",
        "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
        "      print(edge_command)\n",
        "      var1=os.system(edge_command)\n",
        "      if var1==0:\n",
        "        pass\n",
        "      else:\n",
        "        print(f\"Failed: {i}\")\n",
        "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
        "      k+=1\n",
        "    print(chunk_audio_list)\n",
        "    merge_audio_files(chunk_audio_list, save_path)\n",
        "  else:\n",
        "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
        "    print(edge_command)\n",
        "    var2=os.system(edge_command)\n",
        "    if var2==0:\n",
        "      pass\n",
        "    else:\n",
        "      print(f\"Failed: {chunks_list[0]}\")\n",
        "  return save_path\n",
        "\n",
        "\n",
        "text = 'This is Phi-3-vision-128k-instruct Demo'  # @param {type: \"string\"}\n",
        "Language = \"English\" # @param ['English']\n",
        "\n",
        "Gender = \"Female\"# @param ['Male', 'Female']\n",
        "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
        "speed = 1  # @param {type: \"number\"}\n",
        "translate_text_flag  = False\n",
        "long_sentence = False # @param {type:\"boolean\"}\n",
        "save_path = '/content/edge.wav'  # @param {type: \"string\"}\n",
        "if len(save_path)==0:\n",
        "  save_path=tts_file_name(text)\n",
        "if Language == \"English\" :\n",
        "  if Gender==\"Male\":\n",
        "    voice_name=\"en-US-ChristopherNeural\"\n",
        "  if Gender==\"Female\":\n",
        "    voice_name=female_voice\n",
        "    # voice_name=\"en-US-AriaNeural\"\n",
        "\n",
        "\n",
        "if translate_text_flag:\n",
        "  input_text=text\n",
        "  # input_text=translate_text(text, Language)\n",
        "  # print(\"Translateting\")\n",
        "else:\n",
        "  input_text=text\n",
        "if long_sentence==True and translate_text_flag==True:\n",
        "  chunks_list=make_chunks(input_text,Language)\n",
        "elif long_sentence==True and translate_text_flag==False:\n",
        "  chunks_list=make_chunks(input_text,\"English\")\n",
        "else:\n",
        "  chunks_list=[input_text]\n",
        "# print(chunks_list)\n",
        "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
        "# from IPython.display import clear_output\n",
        "# clear_output()\n",
        "# from IPython.display import Audio\n",
        "# Audio(edge_save_path, autoplay=True)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Audio\n",
        "if not os.path.exists(\"/content/audio\"):\n",
        "    os.mkdir(\"/content/audio\")\n",
        "import uuid\n",
        "def random_audio_name_generate():\n",
        "  random_uuid = uuid.uuid4()\n",
        "  audio_extension = \".mp3\"\n",
        "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
        "  return random_audio_name\n",
        "def talk(input_text):\n",
        "  global long_sentence,translate_text_flag,Language,speed,voice_name\n",
        "  if long_sentence==True and translate_text_flag==True:\n",
        "    chunks_list=make_chunks(input_text,Language)\n",
        "  elif long_sentence==True and translate_text_flag==False:\n",
        "    chunks_list=make_chunks(input_text,\"English\")\n",
        "  else:\n",
        "    chunks_list=[input_text]\n",
        "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
        "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
        "  return edge_save_path\n",
        "\n",
        "\n",
        "edge_save_path=talk(text)\n",
        "Audio(edge_save_path, autoplay=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ah4V-OqbgDfS"
      },
      "outputs": [],
      "source": [
        "#@title utils for graido\n",
        "\n",
        "import uuid\n",
        "def random_image_name():\n",
        "  random_uuid = uuid.uuid4()\n",
        "  image_extension = \".jpg\"\n",
        "  random_image_name = str(random_uuid)[:8] + image_extension\n",
        "  return random_image_name\n",
        "import shutil\n",
        "import os\n",
        "import uuid\n",
        "from PIL import Image\n",
        "\n",
        "if not os.path.exists(\"/content/upload\"):\n",
        "    os.mkdir(\"/content/upload\")\n",
        "\n",
        "def process_upload_image(prompt, gradio_image):\n",
        "    print(gradio_image)\n",
        "    print(type(gradio_image))\n",
        "    try:\n",
        "        # Handle PIL format image\n",
        "        image = Image.open(gradio_image)\n",
        "        # Generate a random image name using UUID\n",
        "        image_name = random_image_name()\n",
        "        # Save the image to the upload directory\n",
        "        copy_image_path = os.path.join(\"/content/upload\", image_name)\n",
        "        print(f\"Upload Image Saved at {copy_image_path}\")\n",
        "        image.save(copy_image_path)\n",
        "        answer=ask_question(prompt,copy_image_path)\n",
        "        edge_save_path=talk(answer)\n",
        "        return edge_save_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        copy_image_path=f\"/content/upload/{random_image_name()}\"\n",
        "        gradio_image.save(copy_image_path)\n",
        "        print(f\"Upload Image Saved at {copy_image_path}\")\n",
        "        answer=ask_question(prompt,copy_image_path)\n",
        "        edge_save_path=talk(answer)\n",
        "        return edge_save_path\n",
        "\n",
        "# # Example usage:\n",
        "# gradio_image_path = \"/content/monalisa.jpg\"  # Replace with the actual path to your image\n",
        "# prompt = \"What's going on? Respond with a single sentence.\"\n",
        "# process_upload_image(prompt, gradio_image_path)\n",
        "# gradio_image_path = Image.open(\"/content/monalisa.jpg\")\n",
        "# process_upload_image(prompt, gradio_image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3bXnGwosiSAf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "faaf4c50-d1cd-4831-a39b-ff024bf81273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://348c7c8264c36c9e39.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://348c7c8264c36c9e39.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#@title Run Gradio app and copy the url [For realtime]\n",
        "\n",
        "import gradio as gr\n",
        "image_inputs=[gr.Textbox(label=\"Write Prompt\",value=\"What's going on? Respond with a single sentence.\"),gr.Image(type='pil',label=\"Upload a Image\")]\n",
        "# image_outputs=[gr.Textbox(label=\"Result\")]\n",
        "image_outputs=[gr.File(label=\"Result\")]\n",
        "\n",
        "app_demo = gr.Interface(fn=process_upload_image, inputs=image_inputs,outputs=image_outputs , title=\"MoonDream\")\n",
        "app_demo.launch(share=True,debug=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ec57668444e4ddb9cffb9a09782528c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87a698a12afd4ad8807e23fd01fde6d4",
              "IPY_MODEL_433f5f31986740b08ea2441d343329e5",
              "IPY_MODEL_3ee9a98ad3c447d5a5726a2142ac7e7f"
            ],
            "layout": "IPY_MODEL_26147d1049b44c7d838254b7a7944a8a"
          }
        },
        "87a698a12afd4ad8807e23fd01fde6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88eb60bdc17c429186808823398f7675",
            "placeholder": "",
            "style": "IPY_MODEL_a729d4d1bc504a5788636c30d163681c",
            "value": "Loadingcheckpointshards:0%"
          }
        },
        "433f5f31986740b08ea2441d343329e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69c9401a0344dddb9cac005807e3042",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f65900fe293b4ea3adf27097a943fdcb",
            "value": 0
          }
        },
        "3ee9a98ad3c447d5a5726a2142ac7e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4dfdbb13da74a2e93cdf676dccc6397",
            "placeholder": "",
            "style": "IPY_MODEL_534c8977fb9a46bfa2de1e3725f3d735",
            "value": "0/2[00:00&lt;?,?it/s]"
          }
        },
        "26147d1049b44c7d838254b7a7944a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88eb60bdc17c429186808823398f7675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a729d4d1bc504a5788636c30d163681c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c69c9401a0344dddb9cac005807e3042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65900fe293b4ea3adf27097a943fdcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4dfdbb13da74a2e93cdf676dccc6397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534c8977fb9a46bfa2de1e3725f3d735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}